\section{Bases and Dimension}

\subsubsection{Exercise 1.6.11} Let \( u  \) and \( v \) be distinct vectors of a vector space \( V  \). Show that if \( \{ u,v \}  \) is a basis for \( V  \) and \( a \) and \( b \) are nonzero scalars, then both \( \{ u + v , au  \}  \) and \( \{ au, bv \}  \) are also bases for \( V  \).

\begin{proof}
    (\( \Rightarrow \)) We want to show that \( \{ u+v , au \}  \) and \( \{ au, bv  \}  \) is a basis for \( V  \); that is, we want to show that \( \{ u +v , au  \}   \)  and \( \{ au, bv  \}  \) is both linearly independent and generates \( V  \). We will start by showing that \( \{ u+v , au \}  \) is linearly independent. Choose scalars \( \delta_{1}, \delta_{2}  \) such that 
    \[  \delta_{1} (u+v) + \delta_{2} (au) = 0 \tag{1}  \]
    with \( \delta_{1} =  \delta_{2} = 0  \). Let us algebraically manipulate (1) into the following form:
    \begin{align*} 
    \delta_{1} u + \delta_{1} v  + (\delta_{2}a) u &= 0.  
\end{align*}
Since \( \{ u,v  \}   \) is linearly independent and \( a \neq 0  \), we get that 
\[  \delta_{1} v + (\delta_{2}a) u = 0   \]
implies \( \delta_{1} = 0  \) and \( \delta_{2}a = 0  \) such that \( \delta_{2} = 0  \). But this implies that \( \{ u+v, au \}  \) is also linearly independent. To show that \( \{ u+v , au \}  \) spans \( V  \), it suffices to show that \( V \subseteq \{ u+v , au \}  \) since the other containment \( \{ u+ v , au  \} \subseteq V  \) follows immediately. Let \( v \in V  \). By Theorem 1.7, we know that adjoining an arbitrary vector \( w \in V  \) but not in \( \{ u+v , au \}  \) creates a linearly dependent set. So, we must have \( w \in \text{span}(\{ u+v , au \} ) \) and thus \( V \subseteq \text{span}(\{ a+v , au \} ) \). 

Now, we want to show that \( \{ au, bv  \}  \) is a basis. Choose scalars \( \delta_{1}, \delta_{2}  \) such that 
\[  \delta_{1} (au) + \delta_{2} (bv) = 0 \tag{2}   \]  
such that \( \delta_{1} = \delta_{2} = 0  \). We can manipulate (2) by rewriting it in the following form: 
\[  (\delta_{1}a) u + (\delta_{2}b) v = 0. \tag{3}  \]
Since \( \{ u,v  \}   \) is a linearly independent set, we know that   \( \delta_{1}a = \delta_{2}b = 0  \). Since \( a,b \neq 0 \), this implies that \( \delta_{1} = \delta_{2} = 0 \). Hence, the representation in (2) is trivial and thus the set \( \{ au, bv  \}  \) is linearly independent. Since adjoining any \( w \in V  \) not in \( \{ au, bv  \}  \) creates a linearly dependent set, we get that \( w \in \text{span}(\{ au,bv \} ) \) by Theorem 1.7. Hence, \( \{ au,bv \}  \) generates \( V  \). 


\end{proof}

\subsubsection{Exercise 1.6.12}
Let \( u,v,  \) and \( w  \) be distinct vectors of a vector space \( V  \). Show that if \( \{ u,v,w \}  \) is a basis for \( V  \), then \( \{ u + v   + w , v + w , w  \}  \) is also a basis for \( V  \). 
\begin{proof}
    First, we prove that \( \{ u+v + w, v + w , w  \}   \) is linearly independent. Choose \( \delta_{1} , \delta_{2} , \delta_{3} \in F  \) such that 
    \[  \delta_{1} (u+v+w) + \delta_{2} (v +w) + \delta_{3} w = 0. \tag{1}  \]
    We can rewrite (1) in the following way:
    \[ (\delta_{1} u + \delta_{2} v + \delta_{3} w ) + \delta_{1} (v+w) + \delta_{2} w  = 0.  \tag{2}.  \]
    Since \( \{ u,v, w \}  \) is also a basis, we know that \( \{ u,v,w  \}   \) is also linearly independent. Hence, \( \delta_{1} = \delta_{2} = \delta_{3} = 0  \). Thus, (1) contains the trivial representation and so \( \{ u + v + w, v + w , w  \}  \) is linearly independent. 

    Now, to prove that \( S = \{ u+v+w, v + w , w  \}   \) generates \( V  \), it suffices to show that \( V \subseteq \text{span}(S) \). Adjoining a vector \( x \in  V  \) but not in \( S  \) produces a linearly independent set. Hence, Theorem 1.7 implies that \( s \in \text{span}(S) \). Hence, \( S  \) generates \( V   \) and that \( S  \) is a basis for \( V  \).

\end{proof}


\subsubsection{Exercise 1.6.20} Let \( V  \) be a vector space having dimension \( n  \), and let \( S  \) be a subset of \( V  \) that generates \( V  \).
\begin{enumerate}
    \item[(a)] Prove that there is a subset of \( S  \) that is a basis for \( V  \). (Be careful not to assume that \( S  \) is finite.)
        \begin{proof}
        Let \( \text{dim}(V) = n  \). Suppose \( S  \) is a subset of \( V  \) such that \( S  \) generates \( V  \). Then \( S  \) could be either \( S = \{ 0  \}   \) or \( S = \emptyset \). In either case, we find that \( \text{span}(\emptyset) = \{  0  \}  = V  \) or \( \text{span}(\{ 0 \} ) = \{ 0 \}  = V  \). Now, suppose \( S  \) contains a non-zero vector \( u_{1} \). Thus, the set \( \{ u_{1} \}  \) is linearly independent. Suppose we continue adding vectors inductively \( u_{2}, u_{3} , \dots, u_{k }  \) into this set such that this process stops at exactly \( k  \) vectors. We claim that our constructed set 
        \[  L = \{ u_{1}, u_{2}, \dots, u_{k } \} \] 
        is linearly independent for \( k \geq 1 \). Suppose we assume that \( L  \) holds for the \( k  \)th case. We want to show that it also holds for the \( k + 1  \) case. Observe that
        \[  L = \{ u_{1}, u_{2} , \dots, u_{k+1} \} = \{ u_{1}, u_{2}, \dots, u_{k } \} \cup \{ u_{k+1} \}.  \] If \( u_{k+1} = 0  \), then \( L   \) would be linearly dependent. Otherwise \( u_{k+1} \neq 0  \) and so \( \{ u_{k+1} \}  \) is linearly independent. By inductive hypothesis, we also know that \( \{ u_{1}, u_{2}, \dots, u_{k } \}  \) is linearly independent. Since \( \text{span}(\{ u_{1}, u_{2}, \dots, u_{k } \}) \cap \text{span}(\{ u_{k+1} \} ) = \{ 0 \}  \) and that the two sets are disjoint, we know that \( \{ u_{1}, u_{2}, \dots, u_{k } \} \cup \{ u_{k+1} \}   \) is linearly independent. This ends our induction proof. 

    Note that we cannot have \( S \neq L   \) since \( S  \) could be an infinite set. Since \( L  \) is a subset of \( V  \) where \( \text{dim}(V) = n  \), \( L  \) can be extended into a basis for \( V  \) by Corollary 2 of the Replacement Theorem that contains exactly \( n  \) vectors.
        \end{proof}
    \item[(b)] Prove that \( S  \) contains at least \( n  \) vectors.
        \begin{proof}
        Denote the basis constructed from part (a) as \( \beta \). Since \( \beta \) is a basis for \( V  \), \( \beta \) must contain exactly \( n  \) vectors. Since \( \beta \subseteq S  \) and \( S  \) is a generating set for \( V  \), then \( S  \) must contain at least \( n  \) vectors.
        \end{proof}
\end{enumerate}

\subsubsection{Exercise 1.6.21} Prove that a vectors space is infinite-dimensional if and only if it contains an infinite linearly independent subset. 
\begin{proof}
\end{proof}


\subsubsection{Exercise 1.6.22} Let \( W_{1} \) and \( W_{2} \) be subspaces of a finite-dimensional vector space \( V  \). Determine the necessary and sufficient conditions on \( W_{1}  \) and \( W_{2} \) so that \( \text{dim}(W_{1} \cup W_{2}) = \text{dim}(W_{1}). \)    
\begin{proof}

\end{proof}

\subsubsection{Exercise 1.6.23} Let \( v_{1}, v_{2}, \dots, v_{k }, v  \) be vectors in a vector space \( V  \), and define \( W_{1} = \text{span}(\{ v_{1}, v_{2}, \dots, v_{k } \} )  \), and \( W_{2} = \text{span}(\{ v_{1}, v_{2}, \dots, v_{k }, v  \} ) \).
\begin{enumerate}
    \item[(a)] Find necessary and sufficient conditions on \( v  \) such that \( \text{dim}(W_{1}) = \text{dim}(W_{2}) \).
        \begin{proof}
        
        \end{proof}
    \item[(b)] State and prove a relationship involving \( \text{dim}(W_{1}) \) and \( \text{dim}(W_{2}) \) in the case that \( \text{dim}(W_{1}) \neq \text{dim}(W_{2})  \).
        \begin{proof}
        
        \end{proof}
\end{enumerate}

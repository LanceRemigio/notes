\section{Linear Combinations}

\subsubsection{Exercise 1.4.7} In \( F^{n}  \), let \( e_{j}  \) denote the vector whose \( j \)th coordinate is \( 1  \) and whose other coordinates are 0. Prove that \( \{ e_{1}, e_{2}, \dots, e_{n} \}  \) generates \( F^{n} \).
\begin{proof}
Denote the set \( V = \{ e_{1}, e_{2}, \dots, e_{n} \}  \). Our goal is to find scalars \( \delta_{1}, \delta_{2} , \dots, \delta_{n} \in F  \) such that for all \( e_{j} \in V   \) for \( 1 \leq j \leq n  \), 
\[  \delta_{1} e_{1} + \delta_{2} e_{2} + \cdots + \delta_{n} e_{n} = (a_{1}, a_{2}, \dots, a_{n}). \tag{1} \]
Since \( e_{j} = 1  \) for the \( j \)th  coordinate and the rest of the entries are zeros, we have that 
\[  \delta_{j} e_{j} = \delta_{j} (0, 0, \underbrace{1}_{j\text{th entry} } , \dots, 0) = (0 , 0 , \delta_{j} , \dots , 0 ) \]  for all \( 1 \leq j \leq n  \).
Summing up each term on the left side of (1) and equating each coordinate to the right side of (1), we get that  \( a_{j} = \delta_{j}  \) for each \( 1 \leq j \leq n   \). Hence, the set \( V  \) can span the vector space \( F^{n}  \).

\end{proof}

\subsubsection{Exercise 1.4.8} Show that \( P_{n}(F) \) is generated by \( \{ 1 ,x , \dots , x^{n} \}  \).
\begin{proof}
Let \(  V = \{ 1 , x , \dots, x^{n} \}  \). We need to find scalars \( \delta_{1}, \delta_{2}, \dots, \delta_{n} \in F  \) such that 
\[ \delta_{0} + \delta_{1} x + \delta_{2} x^{2} + \cdots + \delta_{n} x^{n} = a_{0} + a_{1} x + a_{2} x^{2} + \cdots + a_{n} x^{n}.  \tag{1}       \]
Immediately, we have that equating coefficients in (1) gives us \( a_{i} = \delta_{i}  \) for all \( 1 \leq i \leq n  \). Hence, \( V  \) generates \( P_{n}(F) \). 
\end{proof}

\subsubsection{Exercise 1.4.9} Show that the matrices
\begin{center}
    \( \begin{pmatrix}
        1 & 0 \\
        0 & 0 
    \end{pmatrix} \), \( \begin{pmatrix}
        0 & 1 \\ 
        0 & 0 
    \end{pmatrix} \), \( \begin{pmatrix}
        0 & 0 \\
        1 & 0 
    \end{pmatrix} \), and  \( \begin{pmatrix}
        0 & 0 \\
        0 & 1 
    \end{pmatrix} \)
\end{center}
generate \( M_{2 \times 2 }(F) \).
\begin{proof}
    Define \( V  \) with the given \( 2 \times 2  \) matrices above. We need to find scalars \( \delta_{i} \in F  \) for all \( 1 \leq i \leq 4 \) such that
    \begin{align*}
        \delta_{1} \begin{pmatrix}
            1 & 0 \\
            0 & 0 
            \end{pmatrix} + \delta_{2} \begin{pmatrix}
            0 & 1 \\
            0 & 0 
        \end{pmatrix} + \delta_3 \begin{pmatrix}
            0 & 0 \\
            1 & 0 
            \end{pmatrix} + \delta_{4} \begin{pmatrix}
            0 & 0 \\
            0 & 1 
        \end{pmatrix} &= \begin{pmatrix}
        a_{11}  &  a_{12} \\
        a_{21} & a_{22} 
    \end{pmatrix}.  \tag{1}   \\
    \end{align*}
    Distributing each scalar \( \delta_i  \) for all \( 1 \leq i \leq 4  \) for each term in (1), summing up each matrix in (1), and equating each term entry-wise, we have that \( a_{11} = \delta_{1}, a_{12} = \delta_{2} , a_{21} = \delta_{3} ,   \) and \( a_{22} = \delta_{4}  \). Hence, \( V  \) spans \( M_{2 \times2 }(F) \).
\end{proof}

\subsubsection{Exercise 1.4.10} Show that if 
\begin{center}
    \( M_{1} = \begin{pmatrix}
        1 & 0 \\
        0 & 0 
    \end{pmatrix} \), \( M_{2} =  \begin{pmatrix}
        0 & 0 \\ 
        0 & 1 
    \end{pmatrix} \), and 
    \( M_{3} = \begin{pmatrix}
        0 & 1 \\
        1 & 0 
    \end{pmatrix} \),
\end{center} then the span of \( \{ M_{1} , M_{2} , M_{3} \}  \) is the set of all symmetric \( 2 \times 2  \) matrices.

\begin{proof}
We need to show that the set \( \{  M_{1}, M_{2}, M_{3} \} \) spans the set of all symmetric \(  2 \times 2  \) matrices. We need to find scalars \( a_{1} , a_{2} , a_{3}  \) such that 
\[  a_{1} M_{1} + a_{2} M_{2} + a_{3} M_{3} = \begin{pmatrix}
    \delta_{11} & \delta_{12} \\
    \delta_{21} & \delta_{22}
\end{pmatrix} = A  \tag{1}  \]
where \( A  \) is any \( 2 \times 2  \) symmetric  matrix.  Observe that for \( i = j  \), we have \( \delta_{12} = \delta_{21} \). Performing scalar multiplication on matrices \( M_{1}, M_{2},  \) and \( M_{3} \), addition of all three terms on (1), and equating entry-wise, we get that \( \delta_{12} = \delta_{21} = \delta_{3} \) and \( \delta_{11} = \delta_{1}  \) and \( \delta_{2} = a_{22} \). Hence, we have
\[  
 \begin{pmatrix}
    a_{1} & a_{3} \\
    a_{3} & a_{2} 
\end{pmatrix}^{t} =  \begin{pmatrix}
    a_{1} & a_{3} \\
    a_{3} & a_{2} 
\end{pmatrix}.    \]
Thus, the set \( \{ M_{1}, M_{2}, M_{3}  \}   \) spans the set of all symmetric \( 2 \times 2  \) matrices.
\end{proof} 

\subsubsection{Exercise 1.4.11} Prove that \( \text{span}(\{x\} ) = \{ ax : a \in F  \}  \) for any vector \( x  \) in a vector space \( V  \). Interpret this result geometrically in \( \R^{3} \).
\begin{proof}
We need to show that \( \text{span}(\{ x \} ) = \{ a x : a \in F  \}  \), we need to show two containments; that is, \( \text{span}(\{ x \} ) \subseteq \{ ax : a \in F  \}  \) and \( \{ ax : a \in F  \} \subseteq \text{span}(\{ x \} ) \). Let \( v \in \text{span}(\{ x \} ) \). Then observe that we can find \( \delta \in F  \) such that multiplying by \( x \in V  \) leads \( v = \delta x     \). But this means that \( v \in \{ ax : a \in F  \}  \) by definition. Hence, \( \text{span}(\{ x \} ) \subseteq \{ ax : a \in F  \}    \). Let \( v \in \{ ax : a \in F  \}  \). Then \( v = a x  \) for some \( a \in F  \). But this is a linear combination of \( x  \) that makes \( v  \). So \( v \in \text{span}(\{ x \} ) \) and hence, \( \{ ax : a \in F  \} \subseteq \text{span}(\{ x \} ) \). This result can be viewed as the scaling of vectors in \( \R^{3} \).
\end{proof}

\subsubsection{Exercise 1.4.12} Show that a subset \( W  \) of a vector space \( V  \) is a subspace of \( V  \) if and only if \( \text{span}(W) = W  \). 

\begin{proof}
    ( \( \Rightarrow \)) Let \( W  \) be a subspace of \( V  \). To show that \( \text{span}(W) = W  \), we need to show two containments; that is, \( \text{span}(W) \subseteq W  \) and \( W \subseteq \text{span}(W) \). Clearly, \( W  \) contains itself. Hence, \( \text{span}(W) \subseteq W  \) Theorem 5. Let \( v \in W  \). Since \( W  \) is a subspace, we can find scalars \( a_{1} , a_{2} , \dots. a_{n} \in F  \) and vectors \( w_{1} , w_{2} , \dots, w_{n} \in W  \) such that 
    \[  v = a_{1} x_{1} + a_{2} x_{2} + \cdots + a_{n} x_{n} \in W \]
    using the result in Exercise 1.3.20. But this tells us that \( v \in \text{span}(W) \). Hence, \( W \subseteq \text{span}(W) \).

    ( \( \Leftarrow \) ) Since the span of any subset of \(  W   \) is a subspace and \( W = \text{span}(W)  \), we have that \( W  \) is a subspace as well by Theorem 5.
\end{proof}


\subsubsection{Exercise 1.4.13}  Show that if \( S_{1}  \) and \( S_{2}  \) are subsets of a vector space \( V  \) such that \( S_{1} \subseteq S_{2} \), then \( \text{span}(S_{1}) \subseteq  \text{span}(S_{2}) \). In particular, if \( S_{1} \subseteq S_{2}  \) and \( \text{span}(S_{1}) = V  \), deduce that \( \text{span}(S_{2})  = V \).

\begin{proof}
    Let \( S_{1}  \) and \( S_{2}  \) be subsets of a vector space \( V  \). Let \( v \in \text{span}(S_{1}) \). We can find scalars \( \delta_{1} , \delta_{2}, \dots , \delta_{n} \in F  \) and \( x_{1}, x_{2}, \dots, x_{n} \in S_{1} \) such that 
    \[  v = \delta_{1} x_{1} + \delta_{2} x_{2} + \cdots + \delta_{n} x_{n}.  \]
    Since \( S_{1} \subseteq S_{2} \), we know that \( x_{1}, x_{2}, \dots, x_{n} \in S_{2} \) so we must have \( v \in \text{span}(S_{2}) \). Hence, \( \text{span}(S_{1}) \subseteq \text{span}(S_{2}) \). 

    Now, let \( \text{span}(S_{1}) = V  \). We need to show that \( \text{span}(S_{2} ) = V  \); that is, we need to show \( \text{span}(S_{2}) \subseteq V  \) and \( V \subseteq \text{span}(S_{2}) \). By assumption, \( S_{2} \subseteq V  \) and \( \text{span}(S_{2}) \) is a subspace. Clearly, \( \text{span}(S_{2}) \subseteq V  \). Since \( \text{span}(S_{1})  = V \) and \( \text{span}(S_{1})  \subseteq \text{span}(S_{2})\), we have \( V \subseteq \text{span}(S_{2}) \). Hence, \( \text{span}(S_{2})  = V \).
\end{proof}


\subsubsection{Exercise 1.4.14} Show that if \( S_{1}  \) and \( S_{2}  \) are arbitrary subsets of a vector space \( V  \), then \( \text{span}(S_{1} \cup S_{2} ) = \text{span}(S_{1} ) + \text{span}(S_{2})  \). (The sum of two subsets is defined in the exercises of Section 1.3.)
\begin{proof}
Let \( S_{1}  \) and \( S_{2}  \) be subsets of a vector space \( V \). We need to show \( \text{span}(S_{1} \cup S_{2}) = \text{span}(S_{1}) + \text{span}(S_{2}) \); that is, \( \text{span}(S_{1} \cup S_{2}) \subseteq \text{span}(S_{1}) + \text{span}(S_{2}) \) and \( \text{span}(S_{1} ) + \text{span}(S_{2}) \subseteq \text{span}(S_{1} \cup S_{2}) \). Let \( v \in \text{span}(S_{1} \cup S_{2} ) \). We can find \( \delta_{1} , \delta_{2} , \dots, \delta_{n} \in F  \) such that \( x_{1}, x_{2}, \dots, x_{n} \in S_{1} \cup S_{2}  \) implies that  
\[  v = \delta_{1} x_{1} + \delta_{2} x_{2} + \cdots + \delta_{n} x_{n}. \]
Hence, either \( x_{1} , x_{2}, \dots, x_{n} \in S_{1}  \) or \( x_{1}, x_{2} , \dots, x_{n} \in S_{2} \). If \(  x_{1}, x_{2}, \dots, x_{n} \in S_{1}  \), then  \( v \in \text{span}(S_{1}) \). Since \( \text{span}(S_{2})  \) is a subspace, we know that \( O_{V} \in \text{span}(S_{2})  \).  Hence, \( O_{V} \in \text{span}(S_{1}) \) and \( v \in \text{span}(S_{1}) \) imply that \( v + O_{V} = v \in \text{span}(S_{1}) + \text{span}(S_{2})  \). The other case follows a similar process. Hence, \( \text{span}(S_{1} \cup S_{2} ) \subseteq \text{span}(S_{1})  + \text{span}(S_{2})\).

Let \( s \in \text{span}(S_{1}) + \text{span}(S_{2})  \). Hence, \(s = u + v   \) where \( u \in \text{span}(S_{1})\) and \( v \in \text{span}(S_{2}) \). The former implies that we can find scalars \( a_{1}, a_{2}, \dots, a_{n} \in F    \) such that \( x_{1}, x_{2} , \dots, x_{n} \in S_{1} \) where  
\[  u = \sum_{ i=1 }^{ n } a_{i} x_{i}  \]
and the latter implies that there exists scalars \( b_{1}, b_{2}, \dots, b_{n} \in F    \) such that  \( y_{1}, y_{2} , \dots, y_{n} \in S_{2} \) where 
\[  v = \sum_{ i=1 }^{ n }b_{i} y_{i}. \] Since both \( x_{i} \in S_{1}  \) and \( y_{i} \in S_{2}  \) for all \( 1 \leq i \leq n  \), we have \(  x_{i}, y_{i} \in S_{1} \cup S_{2} \) for all \( 1 \leq i \leq n \). So we must have \( s \in \text{span}(S_{1} \cup S_{2})  \). Hence, \( \text{span}(S_{1}) + \text{span}(S_{2}) \subseteq \text{span}(S_{1} \cup S_{2}) \).
\end{proof}

\subsubsection{Exercise 1.4.15} Let \( S_{1}  \) and \( S_{2}  \) be subsets of a vector space \( V  \). Prove that \( \text{span}(S_{1} \cap S_{2}) \subseteq \text{span}(S_{1}) \cap \text{span}(S_{2})  \). Give an example in which \( \text{span}(S_{2} \cap S_{2} ) \) and \( \text{span}(S_{1} ) \cap \text{span}(S_{2}) \) are equal and one in which they are not unequal.
\begin{proof}
Let \( S_{1}  \) and \( S_{2}  \) be subsets of a vector space \( V  \). Let \( v \in \text{span}(S_{1} \cap S_{2} ) \). Then we can find scalars \( a_{i} \in F  \) and vectors \( x_{i} \in S_{i} \cap S_{2} \) for all \( 1 \leq i \leq  n \) such that 
\[ v = \sum_{ i=1 }^{ n } a_{i} x_{i}.  \]
If \( x_{i} \in S_{1} \cap S_{2}  \) for all \( 1 \leq i \leq n  \), then \( x_{i} \in S_{1}  \) and \( x_{i} \in S_{2} \) for all \( 1 \leq i \leq n \). This implies that \( v \in \text{span}(S_{1})    \) and \( v \in \text{span}(S_{2}) \). Hence, \( v  \in \text{span}(S_{1} ) \cap \text{span}(S_{2}) \). Thus, we conclude that \( \text{span}(S_{1} \cap S_{2}) \subseteq \text{span}(S_{1}) \cap \text{span}(S_{2}) \). 
\end{proof}
\begin{eg}
    Define \( S_{1}  \) as the set
    \[ \{  (1,1,0) \in \R^{3} \}   \] and \( S_{2} \) as the set 
    \[ \{ (1,1,0), (1,0,1), (0,1,1) \in  \R^{3} \}.   \]
    Observe that \( S_{1} \cap S_{2} = \{ (1,1,0) \}   \). The span of \( S_{1}  \) yields the following set \( \{ a(1,1,0) : a \in F \ \text{and} \ (1,1,0) \in \R^{3} \}  \).
\end{eg}




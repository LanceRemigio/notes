\section{Bases And Dimension}

\begin{itemize}
    \item Recall that \( S  \) is a generating set for a subspace \( W  \) and no proper subset of \( S  \) is a generating set for \( W  \), then \( S  \) must be linearly independent. 
    \item Linearly independent sets possess the unique property that every vector that its spanning set generates is unique.
    \item This is property is what allows generating sets to be the building blocks of vector spaces.
\end{itemize}

\begin{definition}[Basis]
    A \textbf{basis} \( \beta \) for a vector space \( V  \) is linearly independent subset of \( V  \) that generates \( V  \). If \( \beta  \) is a basis for \( V  \), we also say that the vectors of \( \beta \) form a basis for \( V  \).
\end{definition}

\begin{eg}
    \begin{itemize}
        \item     Recall that the empty set \( \emptyset \) is linearly independent and that \( \text{span}(\emptyset) = \{ 0 \}  \). The empty set \( \emptyset \) in this case is the basis for the zero vector space.
        \item Note that in \( F^{n}  \), the vectors \( e_{1} = (1,0, \dots, 0 ) \), \( e_{2} = (0,1,0, \dots, 0 ) \dots, e_{n} = (0,0, \dots, 0, 1 ) \) form a basis for \( F^{n} \).
        \item The basis for \( M_{m \times n}(F ) \) is the set of matrices \( E^{ij} \) such that the only nonzero entry is a 1 in the \( i \)th and \( j \)th column.
        \item As we have seen in the last section, the set \( \{ 1, x , x^{2}, \dots, x^{n} \}  \) is a basis for \( P_{n}(F) \).
        \item In \( P(F) \), the set \( \{ 1,x ,x,  x^{2}, \dots \}  \) is a basis. \textit{Bases are not limited to finite sets. They can be infinite.} 
\end{itemize}
\end{eg}

\begin{theorem}[ ]
    Let \( V  \) be a vector space and \( u_{1}, u_{2}, \dots, u_{n}  \) be distinct vectors in \( V  \). Then \( \beta = \{ u_{1}, u_{2},\dots , u_{n}  \}   \) is a basis for \( V  \) if and only if each \( v \in V  \) can be unique expressed as a linear combination of vectors in \( \beta \), that is, expressed in the form 
    \[  v = a_{1} v_{1} + a_{2} v_{2} + \cdots + a_{n} v_{n}  \] for unique scalars \( a_{1}, a_{2}, \dots, a_{n}  \).
\end{theorem}
\begin{proof}
    (\( \Rightarrow \)) Suppose \( \beta = \{ u_{1}, u_{2}, \dots, u_{n} \}  \) is a basis for \( V  \). Then \( \text{span}(\beta) = V  \). If \( v \in V  \), then \( v \in \text{span}(\beta) \). Hence, we can write \( v  \) as a linear combination of vectors in \( \beta   \) such that choosing scalars \( a_{1}, a_{2}, \dots, a_{n} \in F  \) leads to 
\[ v = \sum_{ i=1 }^{ n } a_{i} u_{i}.   \]
Suppose there exists another representation of \( v \in V  \) such that 
\[  v = \sum_{ i=1 }^{ n  } b_{i} x_{i} \]
Hence, observe that 
\begin{align*}  &\sum_{ i=1  }^{ n } a_{i} x_{i} = \sum_{ i=1 }^{ n } b_{i} y_{i}  \\
    &\implies \sum_{ i=1 }^{ n } (a_{i} - b_{i}) x_{i} = 0.
\end{align*}
Since \( \beta \) is linearly independent, we know that \( a_{i} - b_{i} = 0  \) which implies \( a_{i} = b_{i}  \) for all \( 1 \leq i \leq n \). Hence, \( v  \) can be expressed as a unique linear combination of vectors in \( \beta \).

(\( \Leftarrow \)) Conversely, let \( v \in V  \) be expressed as a unique linear combination of vectors in \( \beta \) such that 
\[  v = a_{1} u_{1} + a_{2} u_{2} + \cdots + a_{n} u_{n} \tag{1}  \]
for unique scalars \( a_{1}, a_{2}, \dots , a_{n}  \). We want to show that \( \beta   \) is a basis for \( V  \); that is, we want to show that \( \beta \) is a spanning set for \( V  \) and \( \beta \) is linearly independent. To show that \( \beta \) is a spanning set for \( V  \), we need to show that \( \text{span}(\beta) \subseteq V  \) and \( V \subseteq \text{span}(\beta) \). Note that \( \beta \subseteq V  \) and \( \text{span}(\beta) \) is a subspace for \( V  \). Hence, \( \text{span}(\beta) \subseteq V  \). On the other hand, \( V \subseteq \text{span}(\beta) \) follows immediately from (1). To show that \( \beta \) is linearly independent, we need to show that for scalars \( \delta_{1}, \delta_{2}, \dots, \delta_{n}  \), we have
\[ \delta_{1} u_{1} + \delta_{2}u_{2} + \cdots + \delta_{n} u_{n} = 0   \] such that  \( u_{i} = 0   \) for all \( 1 \leq i \leq n \). Note that \( v + 0 = v  \). Hence, we can write
\begin{align*}
    \sum_{ i=1 }^{ n } a_{i} u_{i}  + \sum_{ i=1 }^{ n } \delta_{i} u_{i}    &=  \sum_{ i=1 }^{ n } a_{i} u_{i} \\
    \sum_{ i=1 }^{ n } (a_{i} + \delta_{i}) u_{i} &= \sum_{ i=1 }^{ n } a_{i} u_{i} \\
\end{align*} Equating each term in the equation above yields the following equality:
\[ a_{i} + \delta_{i} = a_{i} \implies \delta_{i} = 0    \]
for all \( 1 \leq  i \leq n  \). But this tells us that \( \beta \) is linearly independent and we are done.
\end{proof}

\begin{itemize}
    \item Any vector \(  v \in V  \) can be written as a linear combination of vectors from the basis containing \( u_{1}, u_{2}, \dots, u_{n} \in V  \). 
    \item This determines a unique \( n  \)-tuple of scalars \( (a_{1}, a_{2}, \dots, a_{n}) \) and conversely, each \( n \)-tuple of scalars determines  a unique vector \( v \in V   \) such that each coefficient from the linear combination of \( u_{1}, u_{2}, \dots, u_{n}  \) is an entry from said tuple.
    \item For example, in our vector space \( F^{n} \), \( n  \) is the number of vectors that should be in the basis for \( F^{n} \) which is indeed the case.
    \item In this book, we are only concerned with finite bases.
\end{itemize}

\begin{theorem}[Finite Spanning Set For a Vector Space]\label{Theorem 1.9}
   If a vector space \( V  \) is generated by a finite set \( S  \), then some subset of \( S  \) is a basis for \( V  \). Hence, \( V  \) has a finite basis. 
\end{theorem}
\begin{proof}
    Suppose \( S = \emptyset \) or \( S = \{ 0 \}  \), then \( V = \{  0  \}  \) and \( \emptyset \) is a subset of \( S  \) that is a basis for \( V  \). If \( S  \) neither of these choices, then \( S  \) must contain at least one nonzero vector \( u_{1}  \); that is, \( S = \{ u_{1} \}  \). Since \( u_{1} \) is nonzero, it follows that \( S  \) is a linearly independent set. We can continue this process of adding vectors \( u_{2}, \dots, u_{k } \) into \( S  \) such that \( S  \) is a linearly independent set of \( k  \) vectors. Since \( S  \) is a finite set, we must end with the linearly independent set \( \beta = \{ u_{1} , u_{2}, \dots, u_{n} \}  \). There are two cases for which this occurs, either \( \beta = S  \) or \( \beta \subseteq S  \): 
    \begin{enumerate}
        \item[(i)] Suppose that \( \beta = S  \) (remember that \( \beta \) is a finite set by construction). Then we have \( S  \) is a linearly independent set and spanning set for \( V  \) (since \( S  \) is a finite set that generates \( V  \)). Hence, \( S  \) is a finite basis for \( V  \).
        \item[(ii)] Suppose  \( \beta \subseteq S  \) is a linearly independent set such that adding \( v \in  S  \) where \( v \notin \beta  \) makes a linearly dependent set. We claim that \( \beta  \) is the desired subset of \( S  \) that is a basis for \( V  \). Then we have two cases; that is, either \( v \in \beta  \) or \( v \notin \beta \). Since  \( \beta \subseteq S   \), we know by { \hyperref[Theorem 1.5]{Theorem 1.5} } that \( \text{span}(\beta) \subseteq S  \) (This applies for both cases). It suffices to show that \( S \subseteq \text{span}(\beta) \). If \( v \in \beta  \), then surely \( v \in \text{span}(\beta) \). Hence, we have \( S \subseteq \text{span}(\beta) \).  Suppose \( v \notin \beta  \). Since \( \beta  \) is a linearly independent set, then by { \hyperref[Theorem  1.7]{Theorem 1.7} }, we have that \( \beta \cup \{ v  \}  \) being linearly dependent implies that \( v \in \text{span}(\beta) \). Hence, \( S \subseteq \text{span}(\beta) \). Thus, that both cases implies that \( \beta \) is a spanning set for \( V  \).    
    \end{enumerate}
\end{proof}

This theorem tells us that any spanning set of a vector space \( V  \) can reduced to a finite basis for \( V  \). This is illustrated in the following examples.


\begin{eg}
    Define 
    \[  S = \{ (2,-3,5), (8,-12, 20), (1,0,-2), (0,2,-1), (7,2,0) \} \]
    which can be shown to generate \( \R^{3} \). The idea is to create a proper subset of \( S  \) such that none of the vectors in \( \beta \) are a multiples of each other. In other words, we want a set that is linearly independent; that is, our choices of vectors determine whether a set will be linearly dependent or independent (we want the latter to hold). Say, we pick \( (2,-3,5 ) \) as our first vector in our subset \( \beta \). Right away, we can exclude \( (8,-12,20) \) since it is a multiple of \( (2,-3,5) \). Otherwise, including it would make \( \beta \) linearly dependent (see exercise 9 from section 1.5). Next, add the vectors \( (1,0,-2) \) and \( (0,2,-1) \) since they are not multiples of the other. Narrowing down our set to 
    \[  \beta = \{ (2,-3,5), (1,0,-2), (0,2,-1) \}.  \]
    Note that adding the vector \( (7,2,0) \) makes \( \beta \) linearly dependent, so \( (7,2,0) \) is excluded from the list. Hence, we have arrived at a subset of \( S  \) such that \( \beta \subseteq S  \) is both a linearly independent set and spanning set for \( \R^{3}\).
\end{eg}

The following theorem and its corollaries are the most important results in the Chapter 1.


\begin{theorem}[Replacement Theorem]\label{Replacement Theorem}
   Let \( V  \) be a vector space that is generated by a set \( G  \) containing exactly \( n  \) vectors, and let \( L  \) be a linearly independent subset of \( V  \) containing exactly \( m  \) vectors. Then \( m \leq n  \) and there exists a subset \( H  \) of \( G  \) containing exactly \( n - m  \) vectors such that \( L \cup H  \) generates \( V  \).  
\end{theorem}
\begin{proof}
Let us proceed the proof via induction on \( m  \). Let \( m = 0  \) be our base case. Then we find that \( L = \emptyset  \) is linearly independent set with exactly \( 0  \) vectors. Letting \( H = G   \) gives us the desired result (since \( G  \) contains exactly \( n  \) vectors).
    Now suppose that the theorem is holds for some integer \( m \geq 0  \). We will show that the theorem holds for the \( m + 1  \) case.Let \( L = \{ v_{1}, v_{2}, \dots, v_{m+1} \}  \) be a linearly independent subset of \( V  \) consisting of exactly \( m + 1  \) vectors. By the corollary to { \hyperref[Corollary to Theorem 1.6]{Theorem 1.6} }, we find that \(L' =  \{ v_{1}, v_{2}, \dots, v_{m} \}  \) is a linearly independent set (because \( L' \subseteq L  \) and \( L  \) is linearly independent). Using our induction hypothesis, we can conclude that \( m \leq n  \) and that there exists a subset \( H' =  \{ u_{1}, u_{2}, \dots, u_{n-m} \}  \) of \( G  \) such that \( L' \cup H' \) generates \( V  \). Thus there exists scalars \( a_{1}, a_{2}, \dots a_{m}, b_{1}, b_{2}, \dots, b_{n-m} \) such that  
    \[  v_{m+1} = a_{1} v_{1} + a_{2} v_{2} + \cdots +   a_{m} v_{m} + b_{1} u_{1} + b_{2} u_{2} + \cdots + b_{n-m} u_{n-m} \tag{1}.\] 
    Note that \( n -m > 0  \), \textbf{unless} \( v_{m+1} \) is a linear combination of \( v_{1}, v_{2}, \dots, v_{m} \) which by Theorem 1.7 contradicts the assumption that \( L  \) is a linearly independent set. Hence, \( n > m  \); that is, \( n \geq m + 1  \). Furthermore, some \( b_{i}  \), say \( b_{1}  \) is nonzero, for otherwise we obtain the same contradiction. Solving (1) for \( u_{1}  \), we get 
    \begin{align*}
        u_{1} =  (- b_{1}^{-1} &a_{1}) v_{1} + (- b_{1}^{-1} a_{2}) v_{2} + \cdots + (- b_{1}^{-1} ) v_{m} + (b_{1}^{-1} )v_{m+1}   \\
                               &+ (- b_{1}^{-1} b_{2} ) u_{2} + \cdots + (- b_{1}^{-1} b_{n-m}) u_{n-m}.
    \end{align*}
    Let \( H = \{  u_{2}, u_{3}, \dots, u_{n-m} \}  \). Then \( u_{1} \in \text{span}(L \cup H ) \) and because \( v_{1}, v_{2}, \dots, v_{m} , u_{2}, \dots, u_{n-m}\) are clearly in \( \text{span}(L \cup H ) \), we have that 
    \[ L' \cup H' \subseteq \text{span}(L \cup H).  \]
    
Since \( L' \cup H' \) generates \( V  \) and the fact that \( L' \cup H' \subseteq \text{span}(L \cup H ) \) (note that \( \text{span}(L \cup H)   \) is also a subspace), we know by {\hyperref[Theorem 1.5]{Theorem 1.5}} that \( \text{span}(L' \cup H') \subseteq \text{span}(L \cup H) \). Since \( \text{span}(L' \cup H')  \) generates \( V  \), we know that \( V \subseteq \text{span}(L' \cup H') \subseteq \text{span}(L \cup H ) \). Observe that \( \text{span}(L \cup H ) \subseteq V  \) is true by default. Hence, \( \text{span}(L \cup H ) \) generates \( V  \) and that \( H  \) contains \( (n-m) - 1 = n - (m+1)  \) vectors which concludes our induction proof.
\end{proof}


\begin{corollary}[ ]
   Let \( V  \) be a vector space having a finite basis. Then all bases for \( V  \) are finite, and every basis for \( V  \) contains the same number of vectors. 
\end{corollary}
\begin{proof}

\end{proof}


\section{Subspaces}

\begin{definition}[Subspaces]
   A subset \( W  \) of a vector space \( V  \) over a field \( F  \) is called a \textbf{subspace} of \( V  \) if \( W  \) is a vector space over \( F  \) with the operations of addition and scalar multiplication.
\end{definition}


The most simple examples of subspaces of \( V  \) is \( V  \) itself and the set containing just the zero vector. The latter is denoted as the \textbf{zero subspace} of \( V  \).


We don't have to check all the vector space properties to prove that a subset \( W \) of \( V  \) is a subspace of \( V  \). This is because vectors in any subset of \( V  \) already satisfy all the properties of a vector space. Hence, we need only check that \( W  \) is closed under 
\begin{enumerate}
    \item \textbf{Addition}: \( x + y \in W  \) whenever \( x \in W  \) and \( y \in W  \).
    \item \textbf{Scalar Multiplication}: \( cx \in W  \) whenever \( c \in F  \) and \( x \in W  \).
    \item \( W  \) contains a zero vector.
    \item Each vector in \( W  \) has an additive inverse in \( W  \).
\end{enumerate}

\begin{theorem}[Subspaces]
   Let \( V  \) be a vector space and \( W  \) a subset of \( V  \). Then \( W  \) is a subspace of \( V  \) if and only if the following three conditions hold for the operations defined in \( V  \). 
   \begin{enumerate}
       \item[(a)] \( O \in W  \).
       \item[(b)] \( x + y \in W  \) whenever \( x \in W  \) and \( y \in W  \).
       \item[(c)] \( cx \in W  \) whenever \( c \in F  \) and \( x \in W  \).
   \end{enumerate}
\end{theorem}
\begin{proof}
Suppose \(W \) is a subspace of \( V  \). Since \( W  \) is also a vector space with the operations of addition and scalar multiplication defined in \( V  \). Hence, we know that \( W  \) is closed under addition and scalar multiplication. Note that \( W  \) contains a zero vector \( O' \in W  \) such that for any \( x \in W  \), we have \( x + 0' = x  \). Since \( x  \) is also in \( V  \) (since \( W \subseteq V  \)), we know that \( x + 0 = x  \). Using the cancellation , we can see that \( x + 0' = x + 0 \) implies \( 0' = 0  \). Hence, properties (a), (b), and (c) are satisfied.

Conversely, suppose conditions (a), (b), and (c) hold. We need to show that \( W  \) is a subspace. This tells us that \( W  \) is closed under addition and scalar multiplication in addition to containing the zero vector. Let \( x \in W  \). Since \( W  \) is closed under scalar multiplication, we know that \( (-1)x \in W  \). By part (b) of theorem 2, we know that \( 1 (-x) = -x \in W   \). Hence, \( W  \) contains an additive inverse and we are done.
\end{proof}

The theorem above provides a simpler way to determine whether a given subset of a vector space is a subspace. Instead of using the definition to show that a give subset is a subspace, it is more common to use the result above.

\begin{definition}[Tranpose]
    The \textbf{transpose} of \( A^{t}  \) of an \( m \times n  \) matrix  \( A  \) is the \( n \times m  \) matrix obtained from \( A  \) by interchanging the rows with the columns; that is, \( (A^{t})_{ij}  = A_{ji} \).
\end{definition}

\begin{eg}
    \[ \begin{pmatrix}
        1 & -2 & 3 \\
        0 & 5 & -1
    \end{pmatrix}^{t} =  \begin{pmatrix}
        1 & 0 \\ 
        -2 & 5 \\
        3 & -1
    \end{pmatrix}  \]
    and 
    \[  \begin{pmatrix}
        1 & 2 \\ 
        2 & 3 
        \end{pmatrix}^{t} = \begin{pmatrix}
            1 & 2 \\
            2 & 3
        \end{pmatrix}.\]
\end{eg}

\begin{definition}[Symmetric Matrices]
    A \textbf{symmetric matrix} is a matrix \( A  \) such that \( A^{t} = A  \).
\end{definition}

\begin{itemize}
    \item The easiest example of a symmetric matrix would be a square matrix where \( i = j  \). 
    \item The set \( W  \) of all symmetric matrices in \( M_{n \times n}(F ) \) is a subspace of \( M_{n \times n}(F)  \) since the conditions of Theorem 1.3 hold.
\end{itemize}

We can show that \( W  \) is indeed a subspace.

\begin{enumerate}
    \item The zero matrix is equal to its transpose and hence belongs to \( W  \).
    \item Suppose \( A \in W  \) and \( B \in W  \). Hence, \( A^{t} = A  \) and \( B^{t} = B  \). Hence, we have 
        \[  (A+B)^{t} = A^{t} + B^{t} = A + B \]
        which implies that \( A + B \in W  \).
    \item We have \( A \in W  \) implies \( A^{t} = A  \). Now, let \( a \in F  \). Then we have that \( (aA)^{t} = a A^{t} = aA  \). Hence, \( aA \in W  \).
\end{enumerate}

\begin{eg}
    Let \( n  \) be non-negative integer, and let \( P_{n}(F) \) consist of all polynomials in \( P(F) \) having degree less than or equal to \( n \). We get that \( P_{n}(F) \) is a subspace because:
    \begin{enumerate}
        \item Zero polynomial has degree -1, it is in \( P_{n}(F) \). 
        \item The sum of two polynomials with degrees less than or equal to \( n  \) is another a polynomial less than or equal to \( n  \).
        \item The product of a scalar and a polynomial of degree less than or equal to \( n  \) is a polynomial less than or equal to \( n  \).
    \end{enumerate}
    This tells us that \( P_{n}(F) \) is a subspace of the space of all polynomials.
\end{eg}

\begin{eg}
    Let \( C(\R ) \) denote the set of all continuous real-valued functions defined on \( \R  \). We know that \( C(\R ) \) is a subset of the vector space \( \mathcal{F}(\R , \R ) \) defined in Example 3.  We will show that \( C(\R ) \) is a subspace of \( \mathcal{F}(\R , \R ) \).
    \begin{enumerate}
        \item Note that the zero function \( f(x) = 0    \) for all \( x \in \R  \) of \( \mathcal{F}(\R ,\R ) \) is a continuous real-valued function. 
        \item Let \( f,g \in C(\R )\). Since the sum of \( f   \)  and \( g  \) is also continuous for all \( x \in \R  \), we have that \( f + g  \in C(\R ) \).
        \item Let \( c \in \R  \) and \( f \in C(\R ) \). We have that for any \( x \in \R   \), \( (cf)(x) = cf(x)    \) is a continuous function. Hence, property (c) is satisfied.
    \end{enumerate}
    Hence, \( C(\R ) \) is a subspace.
\end{eg}

\begin{definition}[Upper Triangular]
    An \( m \times n  \) matrix \( A  \) is called \textbf{upper triangular} if all its entries below the diagonal entries are zero; that is, if \( A_{ij} = 0  \) whenever \( i > j  \). 
\end{definition}

\begin{eg}
    Let \( B  \) be an upper triangular \( 3 \times 4  \) matrix 
    \[  B = \begin{pmatrix}
        1 & 2 & 3 & 4 \\
        0 & 5 & 6 & 7 \\
        0 & 0 & 8 & 9
    \end{pmatrix} \]
\end{eg}

\begin{definition}[Diagonal Matrix]
    An \( n \times n  \) matrix \( M  \) is called a \textbf{diagonal matrix} if \( M_{ij} = 0  \) whenever \( i \neq j  \); that is, if all its non-diagonal entries are zero.
\end{definition}

\begin{eg}
    Let \( A  \) be diagonal \(  3 \times 3  \) matrix.
    \[  A = \begin{pmatrix}
        3 & 0 & 0 \\
        0 & -2 & 0 \\
        0 & 0 & 8
    \end{pmatrix} \]
\end{eg}

\begin{eg}
    The set of diagonal matrices is a subspace of \( M_{n \times n}(F)  \). To see why, we have 
    \begin{enumerate}
        \item Let \( O  \) be the zero matrix of \( M_{n \times n }(F) \). Since \( O  \) is also a diagonal matrix, we know that \( O  \) must be in the set of diagonal matrices.
        \item Let \( A, B  \) in the set of diagonal matrices. Let \( i \neq j  \) such that 
            \[  (A +  B)_{ij} =  A_{ij} + B_{ij} = 0 + 0 = 0.  \]
            Hence, \( A + B   \) is a diagonal matrix and so addition is closed.
        \item Let \( A  \) be a diagonal matrix as before and let \( c \in F   \). Let \( i \neq j  \) again, and observe that 
            \[  (cA)_{ij} = cA_{ij} = c \cdot 0 = 0.   \]
            Hence, \( cA   \) is a diagonal matrix and so scalar multiplication is closed.
    \end{enumerate}
    Since the set of diagonal matrices satisfies all properties of theorem 3, we conclude that it is indeed a subspace of \( M_{n \times n }(F) \).
\end{eg}

\begin{definition}[Trace]
    The \textbf{trace} of an \( n \times n  \) matrix \( M  \), denoted \( \text{tr}(M) \), is the sun of the diagonal entries of \( M  \); that is,
    \[  \text{tr}(M) = M_{11} + M_{22} + \cdots + M_{n n }. \]
\end{definition}

The set of all \( n \times n  \) matrices that have a trace equal to zero is a subspace of \( M_{n \times n}(F)  \) (proved in Exercise 6).


\begin{eg}[Non-example]
   Denote \( V  \) as the set of matrices in \( M_{m \times n}(\R ) \) having non-negative entries. The subset \( V  \) is not a subspace because it is not closed under scalar multiplication. We can see this by multiplying any matrix in \( V  \) be a negative number and observe that the entries of said matrix are no longer all non-negative.  
\end{eg}

We can create subspaces out of other subspaces.


\begin{theorem}
   Any intersection of subspaces of a vector space \( V  \) is a subspace of \( V  \).
\end{theorem}

\begin{proof}
Let \( C  \) be a collection of subspaces of \( V  \), and let \( W  \) denote the intersection of the subspaces in \( C  \). Since every subspace contains the zero vector and the intersection \( W  \neq \emptyset  \), the zero vector \( 0 \in W  \). Let \( a \in F  \) and \( x,y \in W  \). Since each subspace of \( C  \) is closed under addition and scalar multiplication, it follows that \( x + y  \) and \( ax  \) are contained each subspace in \( C  \) and hence \(W   \) must be closed under addition and closed under scalar multiplication. Thus, \( W  \) is a subspace of \( V  \) by theorem 3.
\end{proof}

A natural question to ask is whether or not the union of subspaces of a vector space \( V  \) is a subspace of \( V  \) too. We can see that indeed the union of subspaces of \( V  \) satisfy the first first and third property of theorem 3. However, property 2 need not be satisfied all the time. In fact, the union can only be a subspace of \( V  \) if and only if one the subspaces is a subset of the other.


